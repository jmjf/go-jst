# Add JobStatus GET feature

## Get by job id and business date

I want to be able to get a list of job statuses for a job id and business date so I can use the data to report on job status.

Steps:

* Get job id and business date from query parameters.
* Build a DTO with the values, leaving all other values zero-value.
* Call the repo with the DTO to get the data.
* Return the received data.

I'm passing a DTO because I'm conscious of the "query by any values" story and choosing to be slightly ahead and reduce rework vs. passing job id and business date values to the repo.

What can go wrong? What can go right?

* Get job id and business date from query parameters. (receives DTO from controller)
  * If either value is zero value -> invalid query error (HTTP 400).
* Call the repo with the DTO to get the data.
  * If no data found, repo returns not found error.
  * Use case ignores not found and returns empty results as okay.
* Return the received data.

Tests to write:

* `Test_jobStatusUC_GetQuery_ZeroQueryTermReturnsError`
* `Test_jobStatusUC_GetQuery_RepoErrorReturnsError`
* `Test_jobStatusUC_GetQuery_NoDataReturnsEmptyResult`
* `Test_jobStatusUC_GetQuery_DataFoundReturnsResult`

I've written the first test and it's failing because it wants an error but gets `[]` because the use case just returns empty (proves test can fail). Then I added a check for the error condition and returned the error. Test passes.

Wrote the test for repo error. Failing because it's not getting the error it expected. Call the repo and return error if error. Test passes.

Wrote the test for no data. Tested with mock returning a repo "other" error and fails because it gets the error instead of empty result. Change mock to return an empty row, fails because it's getting a "not implemented" error, which is what I have the use case returning at this stage. Add code to handle not found error and change the use case to return the result and nil error. Test passes.

Wrote the test for data okay. Tested with mock returning only one row and it fails because it expects two rows. Tested returning mismatched data and it fails for mismatched data. Change to return correct data. Test passes.

Tests above are for `db_sqlpgx` only.

**COMMIT:** FEAT: add use case to get by job id and business date (not in API yet); add repo code in db_sqlpgx

## Build tests for db_gormpg

I want to build the same tests for `db_gormpg` so I have better test coverage.

Main things to note

* `gorm` doesn't wrap queries in a transaction (does for exec).
* Using `gorm`'s `Where()` method uses `SELECT *`. The `*` needs to be escaped in the regexp like `SELECT \* FROM "JobStatus"`.
* Otherwise, the tests are basically the same except I call `gormBeforeEach()`.
* I renamed the tests for `dbsqlpg` to have `dbsqlpg` in the name so they're consistent with `gorm` tests.

Tests are built and passing.

**COMMIT:** TEST: add unit tests for gorm repo

## Get by any query on values

I want to be able to get a list of job statuses using a query on any combination of values so I have more reporting flexibility.

This story requires building the `WHERE` clause based on data in the query parameters.

If DTO member is not a zero value, add it to values to use. To be usable, (`AppId` || `JobId`) && (`JobTs` || `BusDt`) must be non-zero to reduce the risk of huge result sets. The query only supports equality, not ranges at this stage.

I need a test for the "must be usable" condition--either ORed pair are both false.

I need a test for the "ok data" condition--add a couple of extra values, but I want to test that the WHERE is built correctly, so will need to decide how to test that. I may need a test in the repo package to test the where builder directly.

* For `dbsqlpg`, I need a slice of values and a WHERE clause to add to a base query.
* For `gorm`, I can build the WHERE clause with `@name` placeholders OR I can pass the DTO with a slice of names to use.

For `dbsqlpg`, I need to look at each value. If it is not zero-value, `where += fmt.Sprintf(" AND $%d", n++)` and `values = append(values, value)` where `n` is a counter for the placeholder.

```golang
var where := "WHERE"
var n := 0
var values []any

if len(dto.AppId) > 0 {
  where += "$" + strconv.Itoa(n)
  n++
}
if len(dto.JobId) > 0 {
  if n > 0 {
    where += "AND "
  }
  where += "$" + strconv.Itoa(n)
  n++
}
// etc.

// or I could 
var where := "WHERE"
var values []any
var n := 0

func buildWhere(value any) {
  if n > 0 {
    where += " AND"
  }
  where += " $" + strconv.Itoa(n)
  values = append(values, value)
  n++
}

// then, taking advantage of the closure to make it simpler
if len(dto.AppId) > 0 {
  buildWhere(dto.AppId)
}
if len(dto.JobId) > 0 {
  buildWhere(dto.JobId)
}

return where, values
```

For `gorm`, I can write `dtoToDb(dto) gormModel` to convert the DTO to a value I can use in the second style. I need to assemble a slice of names of non-zero values. This may not be as understandable as a pattern like `dbsqlpg`.

Another solution is to use `fatih/structs`, though it's archived (he's taking a sabbatical since 2018). Several forks with recent updates exist and may be worth looking at. Or maybe just use the original. I only need the `struct.Map()` method. I can `for` over the `map`, which should be clearer. It will make future repos doing queries easier.

I may look for other examples of doing similar in other Go projects to get a sense of how others tackled this problem.

One thing to consider, the query (`req.URL.Query()`) is already a `map[string][]string`. Calling `req.URL.Query()["key"]` or `req.URL.Query().Get("key")` will get the value. (First style can return multiple values, which I don't want, so use `Get()` style.)

Plan

* Controller passes the query map to the use case. (Type to pass `type RequestQuery map[string][]string`.)
* Use case calls converts query map into a `map[string]any` with only allowed keys
  * Define a map allowed field names in the domain that maps query string names to field names. Put next to the domain object.
  * Somewhere, we'll need to ensure types are valid. Not sure if it belongs in the UC, domain, or repo (which already handles several mappings).
  * LATER: Type conversion happens in the repo because I need database-ready types.
* Use case passes map to repo.
* Repo constructs query from map, which has only terms to include.
* Repo runs query and returns result or error.
* Use case returns result or error.
* Controller sets up response based on result or error.

I wrote a function using `reflect` to build a map of JSON tags to field names so I don't need to manually maintain the valid fields map. I'll need to figure out where to place it because it's probably useful elsewhere, but for now, it's in `jobStatus.go`.

I added tests for:

* invalid query returns error (empty, missing job and app ids, missing timestamp and date)
* repo error returns error
* (repo) no data returns empty result (also tests several query terms mapping in repo)
* data found returns result (also tests several query terms mapping)

Added code in use case and repo to satisfy the tests.

When testing by running, I was getting errors from the repo because fields weren't found. I needed to wrap the field name in quotes when building the WHERE clause because my field names are mixed case.

I also saw a message about a "superfluous response.WriterHeader call" from the request logger middleware (line 23). But that line is required or POST won't return an error on duplicate rows. The problem is the order of calls in the controller. The call to `WriteHeader` must come before encoding the response. In the [`http.ResponseWriter` docs](https://pkg.go.dev/net/http#ResponseWriter), "If WriteHeader is not called explicitly, the first call to Write will trigger an implicit WriterHeader(http.StatusOK)." I'm choosing to explicitly write status codes because sometimes I'll have 2xx responses that aren't 200 or might return a 200 with no body. Always calling `WriteHeader()` makes intent clear. So, I moved the call to `WriteHeader` before the JSON encoder `Encode()` call.

As part of testing, I installed `pino-pretty` so I could pipe log output to it so it's more readable. I've added the NodeJS bits to `.gitignore` to avoid possible confusion. But to install it, assuming NodeJS is installed,`npm init` and accept defaults, `npm install -D pino-pretty`, then `go run ... | npx pino-pretty`. I use structure logs because, in the real world, I'd want fairly detailed logs going to Splunk or similar to I could analyze them.

NOTE: The repo for `gorm` does not support the query option yet.

**COMMIT:** FEAT: add get by query for job statuses

## Clean up controllers and use cases

Controllers and use case names are a bit of a mess.

I want to remove "JobStatus" from the names because they're in the "jobStatus" package, so it's redundant.

Decide if we're going to boil all the use cases into a single `UseCases` object with `Add`, etc. methods.

Decide if the controller will be an object or just a function that takes a use case.

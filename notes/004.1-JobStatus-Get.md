# Add JobStatus GET feature

## Get by job id and business date

I want to be able to get a list of job statuses for a job id and business date so I can use the data to report on job status.

Steps:

* Get job id and business date from query parameters.
* Build a DTO with the values, leaving all other values zero-value.
* Call the repo with the DTO to get the data.
* Return the received data.

I'm passing a DTO because I'm conscious of the "query by any values" story and choosing to be slightly ahead and reduce rework vs. passing job id and business date values to the repo.

What can go wrong? What can go right?

* Get job id and business date from query parameters. (receives DTO from controller)
  * If either value is zero value -> invalid query error (HTTP 400).
* Call the repo with the DTO to get the data.
  * If no data found, repo returns not found error.
  * Use case ignores not found and returns empty results as okay.
* Return the received data.

Tests to write:

* `Test_jobStatusUC_GetQuery_ZeroQueryTermReturnsError`
* `Test_jobStatusUC_GetQuery_RepoErrorReturnsError`
* `Test_jobStatusUC_GetQuery_NoDataReturnsEmptyResult`
* `Test_jobStatusUC_GetQuery_DataFoundReturnsResult`

I've written the first test and it's failing because it wants an error but gets `[]` because the use case just returns empty (proves test can fail). Then I added a check for the error condition and returned the error. Test passes.

Wrote the test for repo error. Failing because it's not getting the error it expected. Call the repo and return error if error. Test passes.

Wrote the test for no data. Tested with mock returning a repo "other" error and fails because it gets the error instead of empty result. Change mock to return an empty row, fails because it's getting a "not implemented" error, which is what I have the use case returning at this stage. Add code to handle not found error and change the use case to return the result and nil error. Test passes.

Wrote the test for data okay. Tested with mock returning only one row and it fails because it expects two rows. Tested returning mismatched data and it fails for mismatched data. Change to return correct data. Test passes.

Tests above are for `db_sqlpgx` only.

**COMMIT:** FEAT: add use case to get by job id and business date (not in API yet); add repo code in db_sqlpgx

## Build tests for db_gormpg

I want to build the same tests for `db_gormpg` so I have better test coverage.

Main things to note

* `gorm` doesn't wrap queries in a transaction (does for exec).
* Using `gorm`'s `Where()` method uses `SELECT *`. The `*` needs to be escaped in the regexp like `SELECT \* FROM "JobStatus"`.
* Otherwise, the tests are basically the same except I call `gormBeforeEach()`.
* I renamed the tests for `dbsqlpg` to have `dbsqlpg` in the name so they're consistent with `gorm` tests.

Tests are built and passing.

**COMMIT:** TEST: add unit tests for gorm repo

## Get by any query on values

I want to be able to get a list of job statuses using a query on any combination of values so I have more reporting flexibility.

This story requires building the `WHERE` clause based on data in the query parameters.

If DTO member is not a zero value, add it to values to use. To be usable, (`AppId` || `JobId`) && (`JobTs` || `BusDt`) must be non-zero to reduce the risk of huge result sets. The query only supports equality, not ranges at this stage.

I need a test for the "must be usable" condition--either ORed pair are both false.

I need a test for the "ok data" condition--add a couple of extra values, but I want to test that the WHERE is built correctly, so will need to decide how to test that. I may need a test in the repo package to test the where builder directly.

* For `dbsqlpg`, I need a slice of values and a WHERE clause to add to a base query.
* For `gorm`, I can build the WHERE clause with `@name` placeholders OR I can pass the DTO with a slice of names to use.

For `dbsqlpg`, I need to look at each value. If it is not zero-value, `where += fmt.Sprintf(" AND $%d", n++)` and `values = append(values, value)` where `n` is a counter for the placeholder.

```golang
var where := "WHERE"
var n := 0
var values []any

if len(dto.AppId) > 0 {
  where += "$" + strconv.Itoa(n)
  n++
}
if len(dto.JobId) > 0 {
  if n > 0 {
    where += "AND "
  }
  where += "$" + strconv.Itoa(n)
  n++
}
// etc.

// or I could 
var where := "WHERE"
var values []any
var n := 0

func buildWhere(value any) {
  if n > 0 {
    where += " AND"
  }
  where += " $" + strconv.Itoa(n)
  values = append(values, value)
  n++
}

// then, taking advantage of the closure to make it simpler
if len(dto.AppId) > 0 {
  buildWhere(dto.AppId)
}
if len(dto.JobId) > 0 {
  buildWhere(dto.JobId)
}

return where, values
```

For `gorm`, I can write `dtoToDb(dto) gormModel` to convert the DTO to a value I can use in the second style. I need to assemble a slice of names of non-zero values. This may not be as understandable as a pattern like `dbsqlpg`.

Another solution is to use `fatih/structs`, though it's archived (he's taking a sabbatical since 2018). Several forks with recent updates exist and may be worth looking at. Or maybe just use the original. I only need the `struct.Map()` method. I can `for` over the `map`, which should be clearer. It will make future repos doing queries easier.

I may look for other examples of doing similar in other Go projects to get a sense of how others tackled this problem.

One thing to consider, the query (`req.URL.Query()`) is already a `map[string][]string`. Calling `req.URL.Query()["key"]` or `req.URL.Query().Get("key")` will get the value. (First style can return multiple values, which I don't want, so use `Get()` style.)

Plan

* Controller passes the query map to the use case. (Type to pass `type RequestQuery map[string][]string`.)
* Use case calls converts query map into a `map[string]any` with only allowed keys
  * Define a map allowed field names in the domain that maps query string names to field names. Put next to the domain object.
  * Somewhere, we'll need to ensure types are valid. Not sure if it belongs in the UC, domain, or repo (which already handles several mappings).
  * LATER: Type conversion happens in the repo because I need database-ready types.
* Use case passes map to repo.
* Repo constructs query from map, which has only terms to include.
* Repo runs query and returns result or error.
* Use case returns result or error.
* Controller sets up response based on result or error.

I wrote a function using `reflect` to build a map of JSON tags to field names so I don't need to manually maintain the valid fields map. I'll need to figure out where to place it because it's probably useful elsewhere, but for now, it's in `jobStatus.go`.

I added tests for:

* invalid query returns error (empty, missing job and app ids, missing timestamp and date)
* repo error returns error
* (repo) no data returns empty result (also tests several query terms mapping in repo)
* data found returns result (also tests several query terms mapping)

Added code in use case and repo to satisfy the tests.

When testing by running, I was getting errors from the repo because fields weren't found. I needed to wrap the field name in quotes when building the WHERE clause because my field names are mixed case.

I also saw a message about a "superfluous response.WriterHeader call" from the request logger middleware (line 23). But that line is required or POST won't return an error on duplicate rows. The problem is the order of calls in the controller. The call to `WriteHeader` must come before encoding the response. In the [`http.ResponseWriter` docs](https://pkg.go.dev/net/http#ResponseWriter), "If WriteHeader is not called explicitly, the first call to Write will trigger an implicit WriterHeader(http.StatusOK)." I'm choosing to explicitly write status codes because sometimes I'll have 2xx responses that aren't 200 or might return a 200 with no body. Always calling `WriteHeader()` makes intent clear. So, I moved the call to `WriteHeader` before the JSON encoder `Encode()` call.

As part of testing, I installed `pino-pretty` so I could pipe log output to it so it's more readable. I've added the NodeJS bits to `.gitignore` to avoid possible confusion. But to install it, assuming NodeJS is installed,`npm init` and accept defaults, `npm install -D pino-pretty`, then `go run ... | npx pino-pretty`. I use structure logs because, in the real world, I'd want fairly detailed logs going to Splunk or similar to I could analyze them.

NOTE: The repo for `gorm` does not support the query option yet.

**COMMIT:** FEAT: add get by query for job statuses

## Support query with gorm

I want to support the query capability with `gorm` so I'm consistent across my main database options.

Replicate tests from `useCases_DbSqlPg_test.go` in `useCases_Gorm_test.go`

Change `gorm/repo.go` to handle queries.

Tests pass.

`fieldToDb()` and `queryToWhere()` are the same in both repos, so now I need a `db` package, which will hold these functions. I want it to hold the repo interface too, but that creates a circular dependency (`db` requires `jobStatus` for `JobStatus` type; use cases are part of `JobStatus` and require `db.Repo`). I want to untangle that, but will do it in the cleanup story below. For now, establish db and start using it.

Update `infra/gormpg/modinit.go` to set up the query cases.

Update `cmd/httpServer-gormpg/main.go` to pass the new controllers to the route setup.

Now test running it. Which turns up two errors to track down.

Error getting request id `callStack: "httpHandler.go::main.main.Handler.func1::17 <- requestid.go::go-slo/internal/middleware.GetRequestId::24 Code GetReqId | error getting request id"`. Request id is empty because I don't have middleware set up. Copy code from `dbpg` version and it works.

The where string has quotes around field names, which `gorm` doesn't like. Pass `fmtString bool` to `db.QueryToWhere()` and select format string with or without quotes based on it. Actually, this turned out to be incorrect. The repos weren't using `db.QueryToWhere()`. After some a short false trail, I figured that out.

**COMMIT:** FEAT: add get job statuses by query to gorm version

## Clean up controllers and use cases

Controllers and use case names are a bit of a mess.

I want to remove "JobStatus" from the names because they're in the "jobStatus" package, so it's redundant.

### Use cases

Decide if all the use cases will be in a single `UseCases` object with `Add`, etc. methods. Factors to consider:

* UC object carries repo, etc., that use cases need to work.
* Currently, both UC objects have a repo (same repo) only.
* Some UCs will need several things (repo, external services, etc.).
* In the latter cases, passing everything to a function every time I call the use case will be a lot of work.
* Also, the controller would need all the parts for the UC even though it doesn't care about them.
* Currently, each UC does exactly one thing and has exactly one method (`Execute()`).
* If UCs are methods on a single object, the methods may have access to things they don't need.

I think it will be better to have one UC object with several functions because:

* Reduces number of UC objects to track (cognitive load).
* Reduces memory footprint. (Only one UC object and one pointer to the repo instead of several.)
* Simplifies setup.
* Controller will have `uc JobStatusUC` and call `uc.Add()`, which is clearer than `uc.Execute()`.
* UC method access to unneeded things isn't a big risk or issue.

Changes needed:

* In `useCases.go`
  * Rename `AddUseCase` to `UseCase`
  * Rename `NewAddUseCase` to `NewUseCase`
  * Rename `jobStatusRepo` to `repo`
  * Rename `Execute` for add to `Add`
  * Rename `Execute` for get by query to `GetByQuery` and attach to `UseCase`
  * Remove `GetByQueryUseCase` and corresponding `New`
* Rename `useCases.go` to `usecase.go` and tests likewise
* Change tests to use new methods and get use case from `beforeEach()`
* Temporarily move controllers to `http` package so `jobStatus` package will compile so tests will run.
* Confirm tests pass.

**COMMIT:** REFACTOR: change use case (use case tests pass, controllers not working)

After looking at controllers, decided to rename to `UseCases` and the rest accordingly. Confirm tests still work.

**COMMIT:** REFACTOR: rename UseCase (use case tests pass, controllers not working)

### Controllers

Decide if the controller will be an object or just a function that takes a use case.

For the same reasons as use cases, make all controllers for the subdomain a single `Controllers` object. This change also lets me set the logger as part of the `New` method so my controllers look more like HTTP handlers, which may be useful when I experiment with `chi`, `gin`, or similar.

Change `modinit`s to use new `UseCases` and `Controllers`.

Change `httpHandler.go` to use `Controllers`.

Change both servers' `main.go` to use the new `modinit`.

Run both servers and confirm they work as expected.

**COMMIT:** REFACTOR: rename Controller (tests pass; servers work)

Where does this "controller" really fit? As written, it's dedicated to HTTP. If I want to support gRPC or some other protocol, I need a separate controller. Are controllers bound to specific infrastructure? Bob Martin would probably say they are because they sit in the adapter layer.

When I look at the controller's `Add()` and `GetByQuery()` methods, the differences are:

* The use case method they call.
* Where they get the data for the use case method.

Other than getting the data and knowing which method to call, they're they same. This is likely to happen for other controllers too. For example, an update or delete controller will have different data and method, but the actually call and handling results will be similar because use cases provide a fairly standard interface. Some methods may not return a JSON body. Some protocols may use different encode/decode strategies and response codes.

If I pull the duplicate code into a function, what would the API look like? This function doesn't know about requests or response writers, so all the data it needs comes from parameters and all the data the caller needs to set up the response comes from the function's return values.

* Function needs:
  * Method to call -- this would need to come from the handler (`switch`).
  * Arguments to pass to the method -- would need to be an arbitrary list (variadic function).
* Function returns:
  * A status code -- For HTTP, status will be an `int`. It looks like gRPC favors returning an `error` and that the Go client can get a status code from the error. But, I can probably return a specific status and let a caller decide how to deal with the response. (For now, I'll use HTTP statuses.)
  * Data to return -- this could be anything or nothing
  * A `LoggableError` maybe -- if I move error logging out to the wrapper

I ended up using generics on this function. Syntax is okay, but error responses aren't handled correctly in HTTP. I found I was always returning the error as `nil` (hangover from an earlier step where I pulled out error handling).

```golang
// callUseCase abstracts calling a use case function and handling the error.
// UCRT is the use case function's primary return type (secondary type is error).
// (Do not use a pointer value for UCRT)
// DT is the type of the data passed to the use case function.
//
// On success, callUseCase returns a *UCRT. The caller must decide how to
// encode the results (data, statuses, etc.).
func callUseCase[UCRT any, DT any](log *slog.Logger, ucFn func(DT) (UCRT, error), reqData DT) (*UCRT, int, error) {
 resStatus := http.StatusOK
 callerNm := "runtime.Caller(1) error"
 pc, _, _, ok := runtime.Caller(1)
 if ok {
  callerNm = runtime.FuncForPC(pc).Name()
 }
 log.Info("callUseCase", "callerNm", callerNm, "fnData", fnData)

 result, err := ucFn(fnData)
 if err != nil {
  logErr := internal.WrapError(err)
  // Need to identify error type and get it for logging
  var le *internal.LoggableError

  // TODO: Get correct error status for loggable error.
  // The error may be an internal server error (e.g., database error).
  // I need a way to choose a response code based on the specific error.
  if errors.As(err, &le) {
   resStatus = http.StatusBadRequest
   internal.LogError(log, le.Err.Error(), logErr.Error(), le)
  } else {
   resStatus = http.StatusInternalServerError
   log.Error("Unknown error type", "err", err)
  }
 }

 log.Info("callUseCase result", "callerNm", callerNm, "result", result, "resStatus", resStatus, "err", err)

 return &result, resStatus, err
}

// example calls
result, resStatus, err := callUseCase[dtoType.JobStatusDTO, JobStatus](ctrl.log, ctrl.uc.Add, dto)
result, resStatus, err := callUseCase[RequestQuery, []JobStatus](ctrl.log, ctrl.uc.GetByQuery, req.Query())
```

**COMMIT:** REFACTOR: move common use case call code into a function (trying a more general controller)

### Remaining

Decide what would need to happen to move the `Repo` interface to the `db` package.

Options:

* Move `jobStatus.go` to a `domain` package.
  * `jobStatus` directory has `usecases` and `controllers` floating in it.
* Move use cases into a separate package -- ends up with `usecases.UseCases`.
  * This means `jobStatus.JobStatus` in a lot of places.

## Request stats

I want to make request statistics to remove query strings from the URL used for the stats key to make the stats more compact.

# Phase 1 -- Job Status -- Work backlog

I have a few items in `999-Backlog.md` to do before I call Phase 1 done.

## When testing with DbSqlPgx, ensure WithArgs() checks argument order

Because I'm using a database library that requires met to write SQL statements and pass arguments manually, SQL argument order is critical to ensure good data.

I want my test database mocks to check argument order so I'm sure the data that will be sent to the database is correct (don't cross column values).

First, I need a time matcher for `sqlmock`. They suggest a basic matcher that accepts anything, but I'll build something slightly more sophisticated. This code is in `jobStatus/useCases_test.go` but probably belongs in a testing utility space.

```golang
type matchTime struct {
  t time.Time
}

func (mt matchTime) Match(v driver.Value) bool {
  v1, ok := v.(time.Time)
  if ok && v1.Compare(mt.t) == 0 {
    return true
  }
  return false
}

// Then in WithArgs

  .WithArgs(matchTime{t: timeToMatch })
```

In `beforeEach()`, I truncate `JobTs` to seconds because it looks like that's happening in `sqlmock` somewhere, so having nanoseconds won't match.

Now, I need a `Match()` on my `Date` type. I considered putting this on the `Date` itself, but decided `Match` is a very generic name. So, I use `matchTime{t: time.Time(dto.BusDt)}`, because `Date` is just a new type of `time.Time`.

**COMMIT:** TEST: use WithArgs() in database tests to ensure parameters are passed correctly

## Pointer receivers vs. value receivers

When attaching methods to a `struct`, the receiver can be a pointer or value. Pointer receivers allow changing the instance referenced. Value receivers work on a copy.

```golang
type MyType struct{
  s string
}

// pointer receiver
func (mt *MyType) SetSPtr(str string) {
  mt.s = str
}

// value receiver
func (mt MyType) SetSVal(str string) MyType {
  mt.s = str
  return mt
}

func main() {
 v := MyType{s: "hello"}
 v.SetSVal("world1")
 fmt.Printf("%+v\n", v)

 v2 := v.SetSVal("world2a")
 fmt.Printf("%+v || %+v\n", v, v2)

 v = v.SetSVal("world2b")
 fmt.Printf("%+v\n", v)

 v.SetSPtr("world3")
 fmt.Printf("%+v\n", v)

 (&v).SetSPtr("world4")
 fmt.Printf("%+v\n", v)
}

/*** OUTPUT
{s:hello}
{s:hello} || {s:world2a}
{s:world2b}
{s:world3}
{s:world4}
***/
```

The compiler does some automatic conversions between pointers and values that work in some cases, but not others (interfaces). Common wisdom is to pick one and use it consistently for a given `struct` type, especially if an interface is in play. Many people lean toward pointers to have a common pattern everywhere.

My general preference is to avoid mutation, so I favor a strategy like the "world2a" and "world2b" examples above (explicitly overwrite). Unexpected mutation is a risk.

Golang does automatic conversions to/from pointers, so I might not know a function is mutating a value unless the function makes it explicit. I expect a setter to mutate and a getter not to mutate. Other functions may be unclear unless I explicitly passes a pointer (`someFunc(&mutateMe)` or `(&mutateMe).someFunc()`). Maybe an easy risk reduction is documentation comments and a consistent statement about whether a function mutates or not.

If the `struct` includes a synchronizing field (`sync.Mutex` or similar), methods must use a pointer receiver because copying the mutex breaks it. For `map`, `func`, `chan`, and slice, value receivers seem to be preferred. These type are the 1x - 3x the size of a pointer, so passing a pointer gets little gain and adds indirection. Small types (`int`, `rune`, etc.) fall into the same space as do small `structs`.

I also read a well reasoned article arguing against passing pointers seeking to avoid the cost of data copying. In modern CPU architectures, parameters passed by value are likely to be in L1/L2/L3 cache. Pointer parameters are more likely to require falling out to RAM, which is slower. The receiver is effectively another parameter to the function so behaves the same. Either decision seems like an optimization choice (value -> in cache -> better performance vs. pointer -> avoid copy -> better performance). There's a tradeoff and the correct answer is, "It depends."

I want to check all interfaces and methods that take a receiver and make them consistent so behavior is predictable, making decisions based on sound understanding of what they need to do.

I want to ensure all methods and interfaces have documentation comments that include a statement about whether a function mutates the receiver or not.

Let's go through file by file starting with `jobStatus`.

* `common.go` -- has no receivers
* `ctrlServeHttp.go` -- has one receiver; no mutation, added doc comments
* `domain.go` -- has no receivers
* `dto.go` -- has receivers; two do not mutate, added doc comments
  * `normalizeTimes` did mutate, now I have in `common/utils.go` a function `common.TruncateTimeToMs(tm time.Time) time.Time`.
* `repoDbSqlPgx.go` -- has receivers; no mutation, added doc comments
* `repoMemory.go` -- has receivers; all mutate the mutex, one mutates data, added doc comments
* `usesCases_test.go` -- has receivers; on `matchDate`, does not mutate, not adding comments because it's used for tests only
* `useCases.go` -- has receivers; none mutate (two are TODO items, but won't mutate), added doc comments

Next `common`.

* `date_test.go` -- has no receivers
* `date.go` -- has receivers; one mutates (`UnmarshalJSON()`, must mutate), added doc comments
* `errors.go` -- has receivers; none mutate, added doc comments
* `utils.go` -- has no receivers

And `cmd/httpServer`, where `main.go` has one receiver. It doesn't mutate and I'm going to ignore it for now because I expect changes in the near future, so will deal with it then. I'm ignoring `cmd/testRepo` because it's a one-off test program that requires changes to base code to work--not production.

I've ended up with a mix of pointer and value receivers, but I think that's legitimate. Only the memory repo (for testing/demo) and `date.go`'s `UnmarshalJSON()`, whose interface I can't control, mutate. Doc comments call out which methods mutate so mutation isn't hidden or accidental.

**COMMIT:** CHORE: apply pointer receivers vs. value receivers based on mutation; note mutation behavior in doc comments

**COMMIT:** CHORE: reorg code in jobStatus a bit (probably more to come)

## Build a repo with gorm, split testing for different repo types

### Research and planning

Looking at [the options](https://github.com/d-tsuji/awesome-go-orms), `gorm` and `sqlx` seem interesting. `gorm` is a fairly traditional ORM that requires writing no SQL. `sqlx` adds syntax sugar to `database/sql`, mainly simplifying scanning and mapping to/from the database. Because `sqlx` is so similar to `database/sql`, I'll build a repo with `gorm` to understand and see differences. I may come back to `sqlx` later.

My main concern with `gorm` is that it's heavily driven by convention and will require overriding to comply with patterns I believe are good.

In an entity-relationship model, an entity represents a single instance of the object, so `gorm`'s automatic plural on table names must be overridden.

`gorm` assumes a column `ID` for the primary key. Using class words on column names (name, date, description, code, id, amount, quantity, count, etc.) helps communicate how they should be used and the general type of information they contain. When using class words, column names must not be a bare class word, so `User.UserId` and `User.ComposedName`, not `User.ID` and `User.Name`, to be explicit about meaning, make reusing metadata easier (20 `ID` columns are a conflict vs. `UserId`, `ProductId`, etc.), and reduce alias column names in foreign keys and joins.

`gorm` assumes columns `CreatedAt` and `UpdatedAt` for tracking create and update. First, the assumed column names are missing classwords (timestamp). Second, if we care when a row was created and updated, we probably want to understand history and change over time. These two columns are inadequate for tracking change over time. `StartTimestamp` and `EndTimestamp` or `EffectiveStartTimestamp` and `EffectiveEndTimestamp` (when was the data "in effect") support history tracking (many rows with the same logical key, but different periods) either in the table or in a separate history table.

I need to think about column naming. I've worked with all-upper snake case names with and without abbreviation (`USR_ID`, `USER_ID`) and upper-first camel case `UserId`. I prefer mixed case names (preference not "best practice") because mixed case faster to read (based on science). `User_Id` may have some advantages, though (word break is more obvious) and I could probably be comfortable with all-lower snake case `user_id`. I'll need to decide which to use.

None of this is to say that `gorm` is bad, just that the conventions are not based on sound entity relationship modeling. (I'm speaking from three decades of experience building ER data models for OLTP and data warehouse systems in small, mid-size, and very large companies.) So, I'll end up with models that override a lot of `gorm` conventions.

The good news is, the database model `struct` lives in the repo and only the repo. I'll export it because I think `gorm` requires that to use it and because I may build an aggregate repo that brings several models together for reporting.

Note that the aggregate repo is not for cases like, "the SLO performance service needs a `JobStatus` to decide which performance data to update." For SLO performance updates, the SLO performance service gets a `JobStatus`, finds all `SLO`s that depend on that job, and updates `SLOPerformance`s for each affected SLO. The same `JobStatus` may set the start time on one `SLOPerformance`, the end time on another, and progress on a third, so the "get `SLO`s" and update are more than one query--unless I try to write a very complex query, which I believe is risky and will make maintenance harder. (I can even see there being an "identify affected SLOs" service that sends a bunch of "SLO performance changed" messages to an SLO performance updater service, with each update happening independently.)

### Build the repo

* Get `gorm` and it's Postgres driver -- `go get -u gorm.io/gorm gorm.io/driver/postgres`.
* Create `jobStatus/repoGormPg.go`.
* Define `gormPgRepo` (only has a `db`).
* Define `GormPgJobStatusModel` (`struct` with annotations and a `TableName()` function).
* Copy `NewDbSqlPgRepo()` and change it to `NewGormPgRepo()`.
* Copy `add()` and `domainToDb()`
  * `domainToDb()` isn't attached to the repo, so is causing a naming conflict. Attach to the repo for both. (Not needed for memory repo.)
* Copy `getPgErrorCode()` (renamed to `getErrorCode()` and attached to repo). Change to use `gorm`'s [errors](https://github.com/go-gorm/gorm/blob/master/errors.go) and [error handling strategy](https://gorm.io/docs/error_handling.html).

`gorm`'s error handling strategy is different, so I end up with code like below. `getErrorFor()` returns the `CommonError` and code mapped to the `gorm` error. Then I create a new error that wraps both so `errors.Is()` will return true for both errors and return `CommonError` with the details. `gorm`'s `Create()` can mutate `dbData`, so I use that as the data body in the error.

```golang
func (repo gormPgRepo) add(jobStatus JobStatus) error {
 // we only care that it succeeds, not looking for a return, so use Exec()
 dbData := repo.domainToDb(jobStatus)
 result := repo.db.Create(&dbData)

 if result.Error != nil {
  ce, ccode := repo.getErrorFor(result.Error)
  err := fmt.Errorf("%w <- %w", ce, result.Error)
  return common.NewCommonError(err, ccode, dbData)
 }

 return nil
}
```

* Copy `getByJobId()` and `rowsToSlice()`
  * Use named arguments and a map for query parameters to avoid ambiguity.
  * Rename `rowsToSlice()` to `rowsToDomain()`
* Use `getByJobId()` to build `getByJobIdBusinessDate()`
  * Add business date to the query parameters and `.Where()` string

### Ensure dbSqlPg still passes tests

I've made changes to `repoDbSqlPgx.go` to align to changes above. (I bound supporting functions to the repo, renamed a few functions, and updated comments.) Run unit tests to ensure it still works. (Passes.)

### Test with http

Rename `cmd/httpServer` to `cmd/httpServer-dbpg`. Copy it and rename `cmd/httpServer-gormpg`. In the latter, connect with `gorm` (below). Then create a `NewGormRepoPg()`.

```golang
 pgDsn := fmt.Sprintf("host=%s user=%s password=%s dbname=%s port=%d sslmode=disable TimeZone=Etc/Utc", userName, password, host, dbName, port)
 fmt.Printf(" -- Connect to %s\n", pgDsn)
 db, err := gorm.Open(postgres.Open(pgDsn), &gorm.Config{
  TranslateError: true,
  // Logger: logger, // doesn't work because gorm's logger interface is different; will need to translate
  NowFunc: func() time.Time { return time.Now().UTC() }, // ensure times are UTC
  // PrepareStmt: true // cache prepared statements for SQL; need to investigate how this works before turning on
 })
 if err != nil {
  logger.Error("gorm.Open failed", "err", err)
  panic(err)
 }
 // gorm doesn't have a Close()
```

I'm getting a connection error that looks familiar. Looking at the "Connect to" log, I have parameters in the wrong order setting up the DSN.

Fixing that, it starts. `POST`ing duplicate data gets a duplicate key as expected (I need to disable `gorm`'s logger). `POST`ing data that isn't duplicate adds it to the database. So, it looks like add is working.

To silence the `gorm` logger, I need to import `gormLogger "gorm.io/gorm/logger"` to get a way to reference it, then in config, `Logger: gormLogger.Default.LogMode(gormLogger.Silent)`. Now the only log messages I'm getting are mine.

My error logs look like below. Note `msg` and `callStack`, which include both my error and `gorm`'s error.

```json
{"time":"2023-07-03T02:15:02.281091312Z","level":"ERROR","msg":"duplicate row error <- duplicated key not allowed","applicationName":"go-slo","serviceName":"jobStatus","hostName":"58651fff4352","pid":41677,"route":"/job-statuses","method":"POST","callStack":"ctrlServeHttp.go::jobStatus.jobStatusCtrl.AddJobStatus::55 <- useCases.go::jobStatus.jobStatusUC.Add::35 <- repoGormPg.go::jobStatus.gormPgRepo.add::49 Code DuplicateRowError | duplicate row error <- duplicated key not allowed","fileName":"repoGormPg.go","funcName":"jobStatus.gormPgRepo.add","lineNo":49,"errorData":"{\"ApplicationId\":\"HTTP 1\",\"JobId\":\"HTTP job 1\",\"JobStatusCode\":\"START\",\"JobStatusTimestamp\":\"2023-07-01T05:19:19+02:00\",\"BusinessDate\":\"2023-06-08T00:00:00Z\",\"RunId\":\"HTTP run 5\",\"HostId\":\"HTTP host a\"}"}
```

I'll just pass the `gorm` error to `NewCommonError()`, like I do on the `dbSqlPg` side.

### Write unit tests

This is the next big thing--figuring out how to test with `gorm`. [This issue](https://github.com/go-gorm/gorm/issues/3565) talks about testing in v2. I tried the code in [avanshee's comment](https://github.com/go-gorm/gorm/issues/3565#issuecomment-1435489310) (`cmd/gmt/gorm_test.go`) and it works. The difficulty about testing this way is that I'll still need to know what SQL it generates (or enough to set up the mock). But, I should be able to use the tests I have with little (no?) change.

I needed to change `beforeEach()` (`gormBeforeEach()`) and add `mock.ExpectBegin()` before and `mock.ExpectCommit()` after, but most tests are working. The only tests failing are for the error conditions. I need to figure out how to return errors to `gorm`. The lines with `SQLSTATE` are coming from `gorm`'s logger, I think. The third error test (other) passes because it's the default case. I also renamed the other `beforeEach()` to `dbSqlPgBeforeEach()` to avoid collisions.

```
=== RUN   Test_jobStatusUC_Gorm_Add_RepoErrors/when_repo_returns_RepoDupeRowError_it_recognizes_the_error

2023/07/03 02:58:56 /workspace/jobStatus/repoGormPg.go:43 :  (SQLSTATE 23505)
[0.205ms] [rows:0] INSERT INTO "JobStatus" ("ApplicationId","JobId","JobStatusCode","JobStatusTimestamp","BusinessDate","RunId","HostId") VALUES ('App1','Job2','START','2023-07-03 02:58:56.398','2023-06-20 00:00:00','Run3','Host4')
    useCasesGorm_test.go:230: FAIL | Expected DuplicateRowError, got repoGormPg.go::jobStatus.gormPgRepo.add::47 Code RepoOtherError | :  (SQLSTATE 23505)
=== RUN   Test_jobStatusUC_Gorm_Add_RepoErrors/when_repo_returns_RepoConnExceptionError_it_recognizes_the_error

2023/07/03 02:58:56 /workspace/jobStatus/repoGormPg.go:43 :  (SQLSTATE 08xxx)
[0.146ms] [rows:0] INSERT INTO "JobStatus" ("ApplicationId","JobId","JobStatusCode","JobStatusTimestamp","BusinessDate","RunId","HostId") VALUES ('App1','Job2','START','2023-07-03 02:58:56.399','2023-06-20 00:00:00','Run3','Host4')
    useCasesGorm_test.go:230: FAIL | Expected ConnectionExceptionError, got repoGormPg.go::jobStatus.gormPgRepo.add::47 Code RepoOtherError | :  (SQLSTATE 08xxx)
=== RUN   Test_jobStatusUC_Gorm_Add_RepoErrors/when_repo_returns_RepoOtherError_it_recognizes_the_error
```

Looking at `gorm`'s Postgres driver's [error translator](https://github.com/go-gorm/postgres/blob/master/error_translator.go), it looks like it only translates two errors to `gorm` errors (23505 and 23503). I'm not sure why 23505 isn't working as expected. (And I wonder if they'd take a PR to expand error translation.)

This commit has a lot of changes, but most of them are related to renames, copies with small changes, the `gorm` example test (`cmd/gmt`), and `go get`ting `gorm`. The main code changes are:

* In `repoDbPgSqlPgx.go`, function renames and bringing all functions under the repo namespace.
* Creating `repoGormPg.go`.
* Creating `useCases_Gorm_test.go`.
* Renaming `useCases_test.go` to `useCases_DbSqlPg_test.go` and renaming `beforeEach()` in it.

**COMMIT:** FEAT: build gorm repo and add tests (two failing)

### Fix failing tests

Running the tests in the debugger, I see the tests aren't configured to translate errors. Also, it may be worth considering that `gorm` doesn't translate many errors, so it may be better to get the plain errors and translate them myself. Because, without translation, I get the `PgError` and could translate the code. That will mean all pg error translation is the same, so I'll want to make it shared (don't duplicate).

* Copy `getErrorCode()` from `repoDbSqlPgx.go` to `common/utils.go` and rename `PgErrorToCommon()`.
* Change calls in both repos to use it.
* Change `gorm` server startup to not translate errors.

I changed `PgErrorToCommon()` to accept an `error` instead of a code. It handles all the translation logic now, so the repo code is much simpler--just get the code and return `NewCommonError()`. I also changed error returns on repo methods to return parameters as a `map[string]any`, which should convert to JSON in logging.

I also moved `matchTime` from the tests to `common/utils.go`, which required a couple of small changes to export it properly.

In the test setup, I want to disable `gorm`'s logger because it's annoying in tests. In fact, I'll copy my `gorm.Config` from `httpServer-gormpg` so it's production-like.

Tests are passing and `gorm` isn't logging in them, let's see how it logs for a duplicate. Simplified `log/slog` setup in `main.go`.

```json
{
  "time":"2023-07-03T14:19:40.826558126Z",
  "level":"ERROR",
  "msg":"ERROR: duplicate key value violates unique constraint \"JobStatus_Primary\" (SQLSTATE 23505)",
  "applicationName":"go-slo",
  "serviceName":"jobStatus",
  "hostName":"58651fff4352",
  "pid":13031,
  "route":"/job-statuses",
  "method":"POST",
  "callStack":"ctrlServeHttp.go::jobStatus.jobStatusCtrl.AddJobStatus::55 <- useCases.go::jobStatus.jobStatusUC.Add::35 <- repoGormPg.go::jobStatus.gormPgRepo.add::46 Code DuplicateRowError | ERROR: duplicate key value violates unique constraint \"JobStatus_Primary\" (SQLSTATE 23505)",
  "fileName":"repoGormPg.go",
  "funcName":"jobStatus.gormPgRepo.add",
  "lineNo":46,
  "errorData":"{\"applicationId\":\"HTTP 1\",\"jobId\":\"HTTP job 1\",\"jobStatusCode\":\"START\",\"jobStatusTimestamp\":\"2023-07-01T05:19:19+02:00\",\"businessDate\":\"2023-06-08\",\"runId\":\"HTTP run 5\",\"hostId\":\"HTTP host a\"}"}
```

This looks okay, except I want to represent `errorData` as a JSON structure, not a string.

**COMMIT:** FIX: use untranslated errors in gorm; tests work, better error handling capabilities

### Log errorData as a structure, not a string

After some digging, the issue was...

In `common/errors.go`, `LogError()` needs to deal with a case where we get an array of errors from `PropsError`. The way I had it written, it was

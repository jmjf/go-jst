# Interlude -- Review code organization

I have enough built that I should be able to think about how I might better organize everything.

I'll drop `cmd/testRepo`. It has served its purpose and is out of sync with changes I've made. There's no value in maintaining it. I can always recover it from commit history.

I want to move the logger setup out of `cmd/httpServer*` so it can be reused in different implementations.

The `common` package could probably be better. How do I organize code that's used in different places so it isn't duplicated without creating something like `common`?

* `date.go` is a data type for date-only times. Enforcing the date only concept in outputs (string, JSON, etc.) is important for some data elements in the problem space. I could have a `date` package.
* `errors.go` could also be a package. The file is reasonably contained. (Can't be called `errors` though. That's a stdlib package.)
* `utils.go` is a bit harder. I could argue that `TruncateTimeToMs` is overkill and I could just inline the code. Then I'm left with `PgErrToCommon()`. It's arguably part of errors, but it's Postgres specific. I'm not sure I want to mingle it with errors. I could have a `MysqlErrToCommon()` or `MongoErrToCommon()`. I'm not sure lumping all those into a single place makes sense (not that `utils.go` solves that either). Would it be crazy to make this injectable? It goes to repos, so maybe. Then it becoms a question of where to put pg vs. mysql vs. etc., stuff. Each would need it's own package in the infrastructure space.

In `jobStatus`, I have:

* `common.go` -- holds the DTO and the repo interface
  * Consider bringing all interfaces here and calling it `interfaces.go`.
* `ctrlServeHttp.go` -- controller for `ServeHttp`
  * Could I make this generic? (Depends on how other options work, needs investigation)
* `domain.go` -- `JobStatus` types, constants, and `new` method
  * Has a lot in common with `common.go`, but it's the internal domain structures, so is conceptually very different.
* `repo*.go` -- repos for data access
  * Consider an `adapters` submodule that would have `common.go` (without non-adapter interfaces), `repo*` and `ctrl*`.
* `useCases.go` -- use cases and tests
  * Many people call these "services", but that term needs a qualifier in DDD.
  * DDD domain service involves application logic that crosses entities (so breaks encapsulation within the domain entity). They often focus action on one entity, but depend on information from other entities to work.
  * DDD application services avoid business logic, just orchestrate data and are closer to the use case concept.
  * I think it's okay for a domain entity to know something about another. So, using an example from [Stemmler](https://khalilstemmler.com/articles/software-design-architecture/domain-driven-design-vs-clean-architecture/), I have no major issues putting the `postService` upvote/downvote logic in the `Post` entity because `PostVote` is a value on the `Post`, the action is about updating the `Post`, and the use case writes the `Post`. (Stemmler does have a `PostVote` repo and table and uses the repo to get the existing votes, but the use case writes `PostVote`s through `postRepo.save()`, not through `postVoteRepo.save()`.)
  * So, what I'm building is closer to use cases (and application service). Bare "service" is unclear. And I'll probably keep domain logic on entities unless there's a very good reason to pull it off.
  * For me, "service" is a type of adapter. For example, if I need to call an API to lookup application data, that's an application service. I might have a verification service, authentication service, authorization service, payment service, etc., that I call. (Phase 2 will add a SLO performance service that the job status service will call to notify it that a new job status has arrived.)

## What parts do I have?

In the overall solution, I'll have:

* A service responsible for receiving and storing job status data.
  * Longer term, I expect HTTP and other receivers feeding a message broker. The write service will subscribe to it, decoupling receipt from actual storage.
* A service responsible for calculating and storing SLO performance based on SLO definitions and job status data.
  * I expect the receiver/writer will notify the calculator/storer--first by HTTP, later by subscribing to a message broker.
  * I need to decide if the calculator/storer will subscribe to a "job status stored" event or a "job status received" event.
* If I assume CQRS could come into play, I may have separate read services. They would need to share the same domain entities.
* Interfaces that describe the data communicated between parts of the system. For example, the HTTP message the job status receiver receives, the table structure it uses, the structure it passes to the calculator/storer.

If I think about this from a layered architecture view, I have:

* Server -- sets up the infrastructure components for a service.
  * I might have separate servers for HTTP, gRPC, and message queue inputs.
  * Their application logic is similar, but they use different infrastructure components to drive it.
* Infrastructure -- code I don't write plus the shims, glue, whatever that I do write to connect it to my adapters.
  * Code I don't write includes `net/http`, `database/sql`, `gorm`, logging, etc.
  * Code I do write includes HTTP handlers that connect the "don't write" code to adapters I do write.
  * Middleware that performs standard request processing tasks (authN/authZ, request id tag, request logging and timing, etc.) varies by mux/router package.
* Adapters -- code I write that bridges a range of infrastructure to use cases.
  * By "a range," I mean a collection of similar code.
  * For example, I should be able to use the same controller with `net/http` and `gin`. But I may need a different controller for gRPC because my controllers are responsible for decoding the request and setting the responses.
* Use cases -- code that executes business processes using domain objects and adapters (repos, services, etc.)
  * If I have separate servers for HTTP and gRPC, they can use the same use cases because the adapters firewall them from the specifics of infrastructure.
* Domain objects -- data structures and types and the data control logic that goes with them
  * Entities, aggregates, domain types, etc.
  * For example, `JobStatus`, `Date`, domain events.
  * Some domain objects are specific to a domain, others (`Date`, for example), are used by many domains.

The job status HTTP receiver server includes:

* Bootstrap code to set up the specific infrastructure components involved.
* Infrastructure like `net/http` (or `gin` or some other mux/router) and handlers for it. Middleware attached to the mux/router.
  * `PgErrToCommon()` would go here in a pg package
* Controller adapters for features connected to handlers and adapters to store the data (in a message broker or a database).
  * Controller for `AddJobStatus`, `GetById`, etc.
  * Repo for the job status data store (`DbSqlPgRepo`, `GormRepo`, etc.)
* Use cases to deliver the business process side of the features
  * Use cases for add and get features.
* Domain objects like `JobStatus`, types and constants like `JobStatusCodeType` and its values, etc.

A gRPC receiver would have different bootstrap and infrastructure code. It probably needs it's own controllers. But it will use the same domain objects, use cases, DTOs, and repo adapters.

So, let's say we have a job status bounded context.

* domain objects -- `JobStatus`, types and constants specific to it; domain specific errors go here
* use cases -- `Add`, `GetById`, etc.
* adapters -- repos, controllers, interfaces and DTOs
* infrastructure -- handlers, building the mux/router for the bounded context, etc.
* server -- bootstrap; would be different for pg vs. mysql, `database/sql` vs. `gorm`, etc.

And an SLO performance bounded context.

* domain objects -- `SloPerformance`, types, constants
* use cases -- `CalculateAndStore`, etc.
* adapters -- repos, controllers, interfaces, DTOs -- probably needs DTOs from other contexts to understand what it's receiving
* infrastructure -- handlers, etc.
* server -- bootstrap

* Same across all servers for a bounded context
  * Domain objects
  * Use cases
* May differ by specific infrastructure components (Postgres vs. MySql; Kafka vs. RabbitMQ; HTTP vs. gRPC)
  * Adapters
  * Infrastructure code I write
* Differ across servers
  * Infrastructure code I don't write
  * Bootstrap code

That's the outline for parts that are specific to a bounded context. But I have some code that should be shared by all bounded contexts (common data types, errors, logger, etc.). Some of the pieces are general, some are infrastructure specific. So I think I'll accept that my overall solution has a `common` or `lib` that follows the same outline. While `common` or `lib` isn't really a feature/capability, it is necessary.

## After some thinking and reading

I've read many posts on project organization, looked at repos on GitHub that claim to be DDD, Clean Architecture, are larger projects, etc., and done a lot of thinking. In the end, Ben Johnson's [post](https://www.gobeyond.dev/packages-as-layers/) here makes a lot of sense to me. I'm still figuring out the bits of his [wtf](https://github.com/benbjohnson/wtf/tree/main) project, but it's mostly making sense to me. so, adapting his model, I've come up with the outline below. Names are tentative.

```
/go-slo
  |-internal
  | |-jobStatus
  | | |-cmd
  | | | |-acceptHttp    (phase 4 http server that accepts POST puts in message broker)
  | | | | |-main.go
  | | | |-HttpApi       (phase 1 http server that accepts GET/POST/etc. requests and does all db actions)
  | | | | | |-main.go
  | | | |-writeToDb     (phase 4 consumes messages and writes to JobStatus table)
  | | | | | |-main.go
  | | |-db              (need to understand possible conflicts between pg and memory)
  | | | |-postgres
  | | | | |-jobStatusRepo.go
  | | | |-inmem
  | | | | |-jobStatusRepo.go
  | | |-http
  | | | |-http.go       (config, sessioning)
  | | | |-jobStatus.go  (routes, route handlers and infra glue code)
  | | | |-server.go     (middleware, router assembly, ServeHTTP or equiv., general routes/handlers (health, 404, auth endpoints, etc.))
  | | |-grpc            (similar to http for gRPC)
  | | | |-server.go     (or whatever)
  | | |-jobStatus.go    (JobStatus, types, constants, domain object methods, primitive errors)
  | | |-useCases.go     (JobStatusUC, UC methods, constants, primitive errors)
  | | |-controllers.go  (JobStatusCtrl, controller methods, constants, primitive errors)
  | | |-go.mod
  | |-sloPerf
  | | |-cmd
  | | |-db
  | | |-http
  | | |-sloPerf.go      (JobStatus, types, constants, domain object methods)
  | | |-useCases.go     (business process logic called by controllers)
  | | |-controllers.go  (JSON to dto, data quality checks, logging)
  | | |-go.mod  
  | |-slo
  | |-sloJob
  | |-logging
  | |-errors
  | |-...
  |-public              (name may change; DTOs defining data contracts)
  | |-jobStatus         (protocols may vary; names may vary; files may be versioned)
  | | |-http
  | | | |-dto20230501.go
  | | | |-dto20230530.go
  | | |-grpc
  | | | |-jobStatus20230501.proto
  | | | |-jobStatus20230501_grpc.pb.go
  | | | |-jobStatus20230501.pb.go
  | | |-kafka
  | | | |-message.go
  | |-sloPerf
  | |-slo
  | |-...
  | |-go.mod
```

* `internal` protects content that shouldn't be used elsewhere.
* `public` exposes information consumers care about (what data will the get or do they need to provide?).
* `cmd` directories within a subdomain maintain that subdomain's data and only that subdomain's data.
  * I'll have a root `cmd` because there's an undefined UI that updates SLOs and defines the jobs, schedules, and other things not shown, so cross subdomain maintenance.
  * A root level `cmd` would also hold any subdomain spanning read/reporting API.
  * It might make more sense to have a root `cmd` only.
* Go builds executables based on packages, so breaking down by subdomain then by adapter types gets smaller executables from `cmd`.
* I may be able to build everything in a single module instead of using a workspace and still compile separate deployables and deploy them independently.
  * This is a bounded context with several subdomains and several services running. I think I want to let subdomains read other subdomains' data (through views) because I believe it will perform better than HTTP/gRPC calls.
  * I say through views because I can change tables without breaking views. I may be able to version views and let different subdomains use different versions of views (`SloJobVw01` in queries below)--up to a point.

On the latter point, I'm thinking SLO performance, on receiving a job status, will want to do something like:

```sql
  UPDATE SloPerf
    SET RunStartTimestamp = @jobTs
    FROM SloPerf sp
      JOIN SloJobVw01 sj
        ON sj.SloId = sp.SloId 
        AND sj.JobId = @jobId 
        AND sj.SequenceNo = 0   /* first job is 0 */
    WHERE sp.Status = "Open"    /* only consider rows that are pending */
    /* or possibly WHERE sp.RunStartTimestamp IS NULL */

  UPDATE SloPerf
    SET RunEndTimestamp = @jobTs
    FROM SloPerf sp
      JOIN SloJobVw01 sj 
        ON sj.SloId = sp.SloId 
        AND sj.JobId = @jobId 
        AND sj.SequenceNo = 999999  /* last job is always 999999 */
    WHERE sp.Status = "Open"        /* only consider rows that are pending */
    /* or possibly WHERE sp.RunEndTimestamp IS NULL */
```

Instead of:

* Call SLO job service to get a list of SLO ids related to the job id and how they're related.
* Split into SLOs where it's the first job and SLOs where it's the last job.
* Update SLO performance data for each SLO or using an `IN` clause.

I don't want to put knowledge about how SLO to job relationships manage their sequence numbers in SLO performance, so I'll want to get their constants. (If the constants are public, that may not matter. Or if I use flags (true/false) to identify first and last jobs.)

**COMMIT:** DOCS: summarize components; notes on organization rethink and direction; remove testRepo

## Reorganize code

Setting up, I changed `.gitignore` so it ignores `db` in the project root only. (Was ignoring `internal/jobStatus/db`.)

I've replaced the workspace with a module (`go-slo`) because importing across directories had issues. I renamed workspace files to `go.workz` and `go.workz.sum` until I figure out which approach I want to use.

Imports and some of the details about module names took some sorting out, but VS Code isn't reporting errors, use cases tests pass, and names make a sort of sense to me for now.

**COMMIT:** CHORE: reorganize code (part 1)

Use cases and controllers need to be rethought.

Use cases represent business processes. They usually have some adapter references (data members) and a function to execute the use case.

I can say a use case object represents all the business processes for it's subdomain. The object has many methods bound to it. The object is named for the subdomain (`JobStatusUC`). All adapters are available to all methods, even if some adapters aren't needed by a specific method. When setting up the service, I create one use case object. Different controllers use the same use case object and call different methods.

I can say a use case object represents a single business process and I have many use case objects for a subdomain. The object has one `Execute()` method bound to it. Each object is named for the process (`AddJobStatus`). The `Execute` method has only the adapters it needs. When setting up the service, I create many use case objects. Different controllers use different use case objects, but all call `Execute()`.

While the "one process, many objects" case suggests an `interface`, different methods return different types on success. For example, `AddJobStatus.Execute()` returns a `JobStatus` on success, but the `Get*` methods return `[]JobStatus`. Go doesn't let me return a union type and I don't want to resort to `any` or similar, so I can't declare a use case interface type at the subdomain level or the top level.

If I use the "one process, many objects" case, my startup is more complex (several UCs). My use case code needs a `struct`, `New*()` that accepts the specific adapters needed, and an `Execute()` for each business process. The `Execute()` method has only the adapters it needs, which protects against unwanted behavior. Controllers get their specific use case(s) so are protected from calling the wrong process or abuse it.

If I use the "many processes, one object" case, my startup is simpler (one UC). The `New()` method takes the superset of adapters needed by all processes. The execute methods are named for the process and could perform actions against adapters they shouldn't use. Controllers get methods for all processes on the single use case and could call the wrong process or abuse it.

I'm opting for a little more work to gain safety and specificity and using the "one process, many objects" approach. So I end up with `AddJobStatusUC`, and `GetJobStatusByQueryUC`. The two "get" cases are by job id and by job id + business date, both of which are queries.  I have no "get by id" use case (yet) because I'm not assigning job status instances ids (yet). I will assign ids in the future and will add `GetJobStatusById` then.

Change applied. Tests updated and passing.

**COMMIT:** REFACTOR: build use cases to perform one business process (many use case types)

Controllers are basically the same as use cases with the same options and similar pros and cons. Currently, I have on controller, so this change should be fairly simple. I will carry this change up to the server so it can run.

Changes made. Both servers (`gormpg` and `dbpg`) run, add rows, return errors and log as expected.

**COMMIT:** REFACTOR: build controller to support one function (many controllers per subdomain)

## Pull logger setup out of httpServer

I want to move the logger setup code in `cmd/httpServer*` to `common/logger.go` so I don't need to duplicate it across server examples.

Consider what other setup may be common and move it there. Review the separation between server and app that I used in Node/TS land. Can I do something similar? And does that let me do mock HTTP tests like I did in Node/TS land?

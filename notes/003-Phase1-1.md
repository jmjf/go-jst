# Getting organized

## Workspace

I did a [side experiment on workspaces](https://github.com/jmjf/go-workspace-experiment) to understand how they work. I plan to have several executables in this bounded context and want to share common code. So, I need to define my modules.

In the same experiment, I sorted out a basic approach for using clean/DDD/hexagonal/whatever architecture, which I'll be using here.

Here's the logical entities I know about:

* `jobStatus` -- includes references to `application` and `job`
* `application`
* `job`
* `slo` -- includes references to `application` and `sloToJob`
* `sloToJob` -- includes references to `slo` and `job`
* `sloPerformance` -- summary of meet/miss data for each SLO period

To resolve the circular reference between `slo` and `sloToJob`, I'll probably make `slo` an aggregate that includes many `sloToJob` in memory. In the database, it's two different tables. I'll also `job` to have `sloToJob`, so I think I'll have something like this:

```golang
// naming pattern TBD, but this way is good for now to draw distinctions

type SloEntity struct {}
type JobEntity struct {}
type SloJobEntity struct {} // carries ids, not jobs or SLOs
type ApplicationEntity struct {}
type JobStatusEntity struct {}
type SloPerformanceEntity struct {}

type SloAggregate struct{
   Slo SloEntity
   SloJobs []SloJobEntity // we need the relationship entity because it has expected start/end times
   // SLO performance could get large so deal with it in slices that have the range of time of interest
}

type JobAggregate struct {
   Job JobEntity
   JobSlo []SloJobEntity // the relationship can go either way
}

type ApplicationAggregate struct {
   Application ApplicationEntity
   ApplicationSlos []SloAggregate // simple relationship with no extra attributes
}
```

I reserve the right to change my mind as I move forward and better understand how to manage the data.

For phase 1, I'm concerned with `JobStatus`. Data from HTTP includes ids for `job` and `application`. I may build an aggregate that includes their details later in phase 1.

So, let's expect we'll have modules for `JobStatus`, `Slo`, `Job` and `Application` at a minumum. For phase 1 I'll focus on `JobStatus` and build the rest out when I'm ready for them.

We can set up the workspace.

```bash
# Cleanup from earlier testing
rm go.mod
rm go.sum
rm testdb.go # it's in commit history when I want to see it

# Create the workspace
go work init
mkdir jobStatus && cd jobStatus && go mod init jobStatus
cd ..
```

I'll sort out how to manage the pg connection later. I may try to build a shared connection object. TBD.

## Job status basics

`domain.go` defines the domain types, constants, and common interfaces

* Basic types
* Constants -- all constants for the module begin with `JobStatus_` and end with an all-caps name (ex: `JobStatus_START`)
* Structs -- `JobStatus` and `JobStatusDto`; latter has JSON tags and uses short field names
* Interfaces -- `JobStatusRepo` and `JobStatusUC`

Build a repo using `database/sql` in `dbSqlRepo.go`. Build a repo using a slice in memory in `memoryRepo.go`. When I start the application, I can create the repo I prefer. Use cases will use the interface, so won't care which implementation I'm using.

For now, I'm leaving `go.work` out of `.gitignore`. Also, I'm changing how I tag commits in markdown files to avoid complaints about full-line emphasis.

**COMMIT:** FEAT: add repos for database/sql and memory; define key data structures; establish workspace

## Next

* Write a simple program to test adding a row with `dbSqlRepo` to confirm `domainToDb()` is working as expected.
* Define and write use cases with unit tests.
* Create tables in pg and think about how to maintain tables.
* Write an HTTP server for job status ingestion.
  * Add logging middleware to log requests, responses, and response times (shared library module).
* Consider writing a `gormRepo` that uses `gorm`.
  * It's an ORM that seems to have key features I'd want, but needs more investigation.

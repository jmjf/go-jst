# Server -- Add middleware

## Add trace id

I want to assign a unique identifier to each request and make it available for logging so I can track the request through the system for debugging and issue investigation.

I want to log the request identifier for all logs related to the request.

In Golang, middleware is a function that returns a `HandlerFunc` that is the middleware. The function accepts an `http.Handler`, usually called `next`. The middleware should hand off to the next thing in the chain by calling `next.ServeHttp(res, req)`, where `res` is the `http.ResponseWriter` and `req` is the `*http.Request` (both received by the middleware).

This pattern isn't that different from Express in NodeJS, except Express middleware accepts `next`, `req`, and `res` in one function.

To assign a unique identifier, I need a source for it. A quick search for options makes me lean toward `segmentio/ksuid` because it's time ordered. Host and process id information will be in logs, so I don't need to add them. For first pass, I'll just increment.

```golang
// addRequestId returns a middleware handler that assigns a request id to the request's context.
func addRequestId(next http.Handler) http.Handler{
   reqId uint64 := 1
   return http.HandlerFunc(func(res http.ResponseWriter, req *http.Request) {
      ctx := context.WithValue(req.Context(), "requestId" , reqId)
      reqId++
      next.ServeHTTP(res, req.WithContext(ctx))
   })
}
```

In other places where I want to log the request id, `requestId := req.Context().Value("requestId")`.

One issue is, context doesn't support type checking (it's `any`), so I may want to extend this with a `type RequestId struct { RequestId uint64 }`, add a getter and setter. Then in the middleware, `ctx := setRequestId(req.Context, &RequestId{ RequestId: reqId })` and `requestId := getRequestId(req.Context)`. Roughly. Think about naming, etc. [ref](https://fideloper.com/golang-context-http-middleware) That detail may be overkill, but in a larger team or with a larger audience, it might be valuable to help ensure consistency.

I'll put middleware in `/lib/middleware`, each middleware in a separate file. For now, I'll make it one package, but may make separate packages later so I don't import unneeded middleware.

To use the middleware, in the server (`cmd/httpServer-dbpg/main.go`)

```
 mux := http.NewServeMux()
 apiMux := http.NewServeMux()

 apiMux.Handle("/job-statuses", jshttp.Handler(logger, addCtrl))
 apiMux.Handle("/job-statuses/", jshttp.Handler(logger, addCtrl))
 mux.Handle("/api/", http.StripPrefix("/api", middleware.AddRequestId(apiMux)))
 mux.Handle("/", logHandler(logger, "/"))
```

While working on this, I figured out how to use a submux. It requires a trailing slash on the upper route: `apiMux.Handle("/api/", http.StripPrefix("/api", handler))`.

I think I have it wired correctly. Now, in the handler that calls the controller, I need to add the request id to the logger (with route and method) so the controller gets the request id.

I added `const requestIdKey` to provide a single control point for the request id's key in the context. I also added `middleware.GetRequestId(ctx context.Context)` to conceal details of how the request id is retrieved. It isn't complex, but the function hides internals and makes the code intent clearer. The function returns 0 if it can't get the request id.

The code is working. I see request id in the log output and it's incrementing.

For now, I'm only putting these changes in `httpServer-dbpg`. I'll add it to `httpServer-gormpg` either after all is done or after pulling the server setup and main into `/internal/jobStatus/cmd`.

**COMMIT:** FEAT: add request id to requests for traceability

## Request logger

I want to log requests received and replied and track request execution time so I can ensure all requests are handled properly, identify invalid requests, and better monitor the system's behavior.

The request logger will need a copy of the application's logger. Output should include the following data.

* `Request.RemoteAddr string`
* `Request.RequestURI string`
* `Request.Method string`
* `RequestId uint64`
* `ReceivedTime time.Time`

I set `const requestLogLevel` so it's easy to change the request log's level. I may test with it at Info but run with it at Debug or Trace to limit log volume. The middleware checks if the logger's handler is enabled for the target level and, if not, doesn't try to log (reduces overhead).

The outer function around the middleware handler accepts both the next handler and the logger.

I have the request and response logging but getting to the response to log response status code and content length is apparently challenging in Golang because it's in the `http.ResponseWriter`. I'll need to do some digging. Most solutions I'm seeing require some new knowledge (parts of stdlib I haven't used yet).

Also, look at how to restructure the code using `defer` to do the response logging. (I'll need to put the logging inside an `if`.)

**COMMIT:** FEAT: Add request logging middleware

## Logging responses

I want to log data about responses returned and track execution time so I have information about successful and failed requests and failure reasons.

I want the response status code and content length at a minimum, possibly more.

Golang doesn't give me direct access to a response with data, it gives a `ResponseWriter`, which is aimed at writing. `ResponseWriter` is an interface with three methods, none of which lend themselves to getting the response details I want.

The cannonical solution seems to be to write a wrapper for `ResponseWriter` with methods that capture data on the wrapper when called and pass the call on to the `ResponseWriter` in the wrapper. The basic version is below.

```golang
type resWriter struct {
 http.ResponseWriter
 status int
 contentLength int
}

func (rw *resWriter) WriteHeader(code int) {
 rw.status = code
 rw.ResponseWriter.WriteHeader(code)
}

func (rw *resWriter) Write(data []byte) (int, error) {
 rw.contentLength += len(data)
 return rw.ResponseWriter.Write(data)
}

func wrapResponseWriter(res http.ResponseWriter) *resWriter {
 return &resWriter{ResponseWriter: res, contentLength: 0}
}
```

There's a package called `httpsnoop` that handles wrapping. The package's readme says wrappers can be a problem because they may miss interfaces that the object behind the `ResponseWriter` implements. [This post](https://blog.kowalczyk.info/article/e00e89c3841e4f8c8c769a78b8a90b47/logging-http-requests-in-go.html) also mentions that the client's IP may be masked by a proxy and outlines ways to get it.

Another option might be to use `httptest.ResponseRecorder`. This type has status, headers, and body available, but I think that would mean taking the data from it and writing it to the real `ResponseWriter`. This approach seems like it will introduce a lot of overhead.

The simple wrapper solution works. I want to understand some of the complexity `httpsnoop` handles and get a better understanding of what might break.

**COMMIT:** FEAT: add status code and content length to response logging with a ResponseWriter wrapper

## Track request stats

I want to accumulate by route and method, total request counts, execution times, success/failure counts, etc., so I can better monitor the system.

I'll use a map with method + route as the key with a `|` separator (example, `POST|/api/job-statuses`). Map entries will be a `struct` (below). In the future, I'll need a mutex in the `struct` if I run parallel request handling.

```golang
type RouteStats struct {
   RequestCount int
   TotalExecTime time.Duration
   Status200Count int   // 200-series statuses
   Status400Count int   // 400-series statuses
   Status500Count int   // 500-series statuses
}
```

~~I want to expand status to include moving window totals for the last hour so I can better monitor the system.~~

Log analysis is a better answer--for both cases, really. But I'll add the basic stats tracker because it's simple and I don't plan to spin up log query tool soon.

The stats tracker needs the response status code. That means it needs to wrap the `ResponseWriter`. If I combine this with `log-request`, I end up with a double wrapped `ResponseWriter`, which seems like a bad idea. The simple answer is to put status tracking in `log-request`. I'm not sure that's wise because it makes `log-request` do more than request logging. On the other hand, I want the time calculated in `log-request` here too, so that may be less unwise than it seems. For now, I'll put stats tracking in `log-request` as separate functions the request logger middleware calls. Doing so makes it clear it's a separate function and makes it easier to remove later if I want to remove it. I'll accept that requests are counted only after the response. (Not perfect, but good enough.)

I'm glad I did that. It revealed that the controller was returning status 0 for ok cases. The server is returning 200, but I'd rather choose my return status and not assume. Added an explicit `WriteHeader(http.StatusOK)` for the ok case.

**COMMIT:** FEAT: add basic per-route statistics tracking (to be replaced in the future)

While working on this section, I decided to rename `CommonError` to `LoggableError` because the latter name better reflects the intent--to provide an error with data that can be logged, mainly within the context of structured logging.

**COMMIT:** REFACTOR: rename CommonError to LoggableError (clearer intent)

## Add a middleware error and return it when "Get" methods fail

I want to return an error when middleware "Get" methods fail so I can safely identify and respond to failures.

As part of this change, I want to move the `lib/middleware` directory to `internal/middleware` because I think this code is less public/reusable (for now) than I thought.

Added `ErrMWGetReqId` and code to `internal/errors.go`. Added error return in `log-request.go` and error logging in functions that use `GetRequestId()`.

**COMMIT:** REFACTOR: add error return for GetRequestId() and handle/log in places that call it

## Generate unique request ids

I want to generate unique request ids so I can identify specific requests across runs and hosts (in a multi-host scenario).

I'm learning toward `segmentio/ksuid`, but may investigate other options.

What do I need in a request id?

My standard logging output includes a timestamp, application name, service name, hostname and pid. If I'm searching logs to trace a specific request, those values should get me to a narrow range of results. For example, if I find an error and want to see the other logs for the error, I'd use some combination of applciation name, service name, hostname and pid from the error to get the request id for that instance.

Assumption: The request is handled on one and only one instance. If that isn't true, a request id in a request header takes precedence; only generate a request id when it isn't provided in the request headers. (New story added.)

This means the main requirement for request id is uniqueness over the life of an instance of the application. Could I stick with my incrementing `uint64`? From a range perspective, probably. Doing a little math, at 100,000 requests per second, the instance would need to run for over 5 million years before it overran the range of `unit64`. (At the same rate, `uint32` would overrun after just under 11 hours, so not a good choice.) But, when tracing across services, ids would lose their uniqueness. For example, if instances A and B call C and A and B both have a request id 1 and C gets request id in a header, C will have logs for A-1 and B-1 with application id, etc., for C and request id 1 for both A and B. That makes tracing B's 1 into C difficult. So I need an id that is unique across instances.

Main options:

* UUID -- well known, ISO/IETF/ITU standards, several variations, 128 bits (36 characters incl. 4 dashes)
* ksuid -- timestamp (32 bits) + random (128 bits) = 160 bits (27 characters, no separators); sorting -> generation time ordered (not sure that's valuable)
* xid -- based on Mongo Object Id, 96 bits (20 characters); sorting -> generation time ordered
* nanoid -- configurable size and alphabet, default (21 characters) has slightly better than UUID uniqueness
* ULID -- custom but UUID "compatible" 128 bits (26 characters Base32); sorting -> generation time ordered to 1ms (within 1ms, random)

I've used nanoid before (in Node/TypeScript). From a performance perspective, xid and nanoid are usually better than UUID. ULID is roughly comparable to UUID performance. I can't find performance metrics on ksuid to compare. But the benchmarks I'm seeing suggest they all run in microseconds or less, so performance probably isn't an issue. If I use the same unique id generator for database keys in the future, having a definite ordering property might be nice (ksuid, xid, ULID).

But, let's understand performance. I found an [id generator benchmark](https://gist.github.com/evalphobia/1f40afcfc73ce207d890dd4b1705a0c9). I copied it into `cmd/idtest/id_test.go` and changed it to run benchmarks for different id generators I'm considering (see imports for specific id generators). Then I ran it with `go test -bench=. -count 20 > run20.txt`. I pulled `run20.txt` into LibreOffice Calc as three columns, parsed the `ns/op` off the last column, converted the result to a number and built a pivot table summarizing the results. (Results below combine two different runs of 20.)

`cpu: Intel(R) Core(TM) i5-6600K CPU @ 3.50GHz`

|Benchmark|Avg Executions|Avg ns/op|Min ns/op|Max ns/op|StDev ns/op|StDev/Avg %|
|---|---|---|---|---|---|---|
|BenchmarkXid-4                  |24472706.5|48.8|48.5|49.0|0.11|0.22%|
|BenchmarkKsuidRand-4            |13862909.4|85.1|84.6|85.8|0.28|0.33%|
|BenchmarkUlidRand-4             |12148360.3|95.9|95.0|97.5|0.61|0.64%|
|BenchmarkJaevorNanoID-4         |9934421.4|118.0|116.7|123.5|1.63|1.38%|
|BenchmarkUlidMake-4             |9742158.1|118.9|117.2|121.5|1.17|0.99%|
|BenchmarkKsuidCryptoRand-4      |996725.2|1176.1|1164.0|1193.0|8.30|0.71%|
|BenchmarkUlidCryptoRand-4       |981048.3|1210.2|1198.0|1224.0|6.84|0.56%|
|BenchmarkUUID-4                 |949441.2|1245.3|1214.0|1308.0|28.57|2.29%|
|BenchmarkMatoousNanoID-4        |823841.1|1391.6|1371.0|1448.0|14.88|1.07%|
|BenchmarkUlidRandMono-4         |201002.7|6265.4|5062.0|8302.0|722.65|11.53%|
|BenchmarkUlidCryptoRandMono-4   |98932.1|11840.9|11686.0|12352.0|149.94|1.27%|

We can break the results into three general groups:

* < 150 ns -- xid, ksuid, ULID-Rand, ULID-Make, and Jaevor's nanoid are all in the same performance ballpark and are all very consistent in their performance range.
* ~1 µs -- Adding crypto random slows ksuid and ULID to about the same performance as UUID and Matoous' nanoid. All are still very consistent in their performance range, with UUID being the least consistent.
* 5+ µs -- ULID with guaranteed monotonic ids.

Which leads to these conclusions:

* Monotonic ids are expensive to generate (10x crypto or 50x rand).
* Crypto-random runs ~12x longer per id than plain-rand variants (exception, Jaevor's nanoid).
* Unless we have huge throughput demand, any of these options work (10µs -> 10,000/second).

Monotonic ids are great if most queries are based on the id. Inserts are guaranteed to happen at the end of the table/index so the database never splits pages. If inserts are the only thing that matters, go monotonic. The problem is, if we insert data into a database (once), we usually want to query it (many times). Most data consumers query on the natural key, not the generated key.

NOTE: The points that follow assume the table isn't small. If the table is small (few pages) and is guaranteed to stay small, query performance is less of a concern.

Data has a natural key, a set of columns that make an instance of the entity unique. For example, for job statuses, we should not have two rows with the same Application Id, Job Id, Job Status Code, Job Status Timestamp, and Business Date. These columns define the natural key of the job status entity.

The job status service needs to ensure it doesn't write duplicate rows if a status provider sends the same update twice. If it blindly uses a generated key, it could. The service query the database to check for a matching key before inserting or updating data and return an error if the key exists. The cost of this check is at least comparable to the cost of the database enforcing uniqueness, likely more expensive.

If humans might insert into or update the table, they should not be able to create duplicate natural keys. Humans can and frequently will choose to insert or update data to "fix a problem," often causing more and more subtle problems that don't appear until much later. (Often after everyone has forgotten the fix, that the business people demanded it against technical advice, etc., leaving the technology team to take the blame and spend much time chasing a non-existent coding error.)

To protect against humans, the database must enforce the uniqueness constraint. We could do that with insert and update triggers, with all the cost, complexity, and database vendor lock-in they introduce. Or we could define a unique index on the natural key. If the natural key index isn't the table ordering index, we incur the cost of storing and maintaining a unique index on the natural key to enforce uniqueness. We also incur the query cost of using that index if the natural key is a common query key, which it usually is. If some queries use the id, the cost of an index on that id is likely less than the cost of an index on the natural key from both an indexing and performance perspective.

So, monotonic ids may enable faster inserts, but may harm performance and data integrity if we need to ensure uniqueness on other columns. Since the argument for monotonic ids is performance, the performance hit could easily outweigh the perceived benefit of monotonic keys. Also, data integrity trumps most other concerns for applications that rely on data. I haven't seen many real-world applications that don't rely on data.

Crypto-grade random may be worth the cost, especially Jaevor's nanoid, which comes in under 150ms per id. Crypto-rand mainly buys better collision avoidance. If id security matters, it is required. Even the other crypto ids, which cost about 12x more than their plain-rand versions are likely okay.

For all the discussion of performance, the data suggests that any of these options is fine. If a service (not instance) needs to handle 10,000 requests/second, it is probably critical and needs to be horizontally scaled for reliability. More instances mean fewer requests/instance. It will also likely be autoscaled to handle traffic bursts and will scale before it overloads because it's critical.

Also consider that, in June 2023, the top 5 websites (`google.com`, `youtube.com`, `facebook.com`, `twitter.com`, `wikipedia.org`) averaged ~163.6 billion page serves **globally** ([source](https://www.semrush.com/website/top/global/all/)). That is ~5.5 billion pages/day, ~227.2 million pages/hour, or ~63,117.5 pages/second. Let's assume a page is bulky 100 requests against the server. These sites use CDN's, load balanced server pools, local mirrors, etc. I don't know how many web server instances are running any one of these domains, but I'm willing to bet it's over 100, so we're still looking at ~63k requests/second.

Few (likely zero) application services will approach a top-5 website's traffic. The ability to handle single-digit thousands of requests per second per instance is adequate rise to this level of traffic. So, any of these options could be acceptable unless the use case is extremely high traffic with subpar infrastructure.

All that said, I think I'll go with Jaevor's nanoid. It's fast. It's easy to use. It's URL-safe. It uses crypto-rand. It's has a few more bits than UUID in fewer characters. The only things it isn't is UUID-compatible (can't be stored in a UUID type) and monotonic (I don't need).

**COMMIT:** CHORE: compare id generators and choose one

Now let's add the id code.

`go get github.com/jaevor/go-nanoid`

Create an id generator (`nanoid.Standard(21)`). It can return errors, so log them (TODO) and default to integer ids (convert to string base 36) for shorter ids and consistent id types.

**COMMIT:** FEAT: use nanoid request ids for better uniqueness

## Allow request ids in request headers

I want to allow requesters to include a request id so I can relate requests across services.

Assume service A calls service B and service B calls service C. I want to be able to relate B's call to C to A's call to B. If A calls B with a request id in a header, B should use that trace id and include it in a header when calling C. Doing so allows log queries to find all the activity related to A's call. If A does not include a request id, B should create a request id, use it call C and include it in a response header (I think).

[OpenTelemetry](https://uptrace.dev/opentelemetry/distributed-tracing.html) defines distributed tracing in terms of spans. Many logging vendors align to OpenTelemetry or do something similar. A distributed transaction trace is a tree of spans. I want to dig into this in more detail, but for now I'm taking a couple of small pieces from it but putting the deeper dive into the backlog.

My focus for this story is HTTP requests. If the caller provides a trace id, I'll use it as is. If the caller doesn't provide a trace id, I want to add something to the base nanoid to reduce risk of collision with caller-generated ids. In the middleware, I can't easily get a parameterized path (for example, `\path\:id`). For job statuses, I don't have a job status id (yet), so my paths will be either plain (`\job-statuses\`) or have a query string (GET must have). So, I'll use the request's `Method` and `URL.Path` as a prefix.

I'll put trace ids the `X-Goslo-Trace-Id` header. I'll return the trace id always so it's available to the caller if the caller doesn't provide it.

In `requestid.go`:

* Add a constant for the trace id header name.
* In the handler, try to get the trace id from the headers.
* If no trace id header, generate an id as before, but add the method and path as a prefix.
* Add the trace id to the context as the request id.
* Add the trace id to the response header. (`res.Header().Set(...)`)

Testing shows it works. Given an `X-Goslo-Trace-Id` header, it uses the header value as request id. Without the header, request id a value with the method, path and generated it. The response headers include either the trace id the caller provided or the trace id the service generated (if no caller provided value).

I'll change the logging name to `traceId` when I dig into OpenTelemetry.

**COMMIT:** FEAT: allow trace ids in request headers and return trace id in response headers

## Find a better way to pass the application's logger to the LogRequest middleware

I want to find a better way to pass the logger to the `LogRequest` middleware so it's easier and less error prone to wrap the middleware.
